---
title: Testing
layout: default
output: bookdown::html_chapter
---

```{r, echo = FALSE}
library(testthat)
```

# 테스팅(Testing) {#tests}

테스팅은 팩키지 개발에서 있어 매우 중요한 부분이다.
테스팅을 통해서 작성한 코드가 의도한 대로 동작하는 것을 확신할 수 있다.
그런 장점에도 불구하구, 테스팅은 개발흐름에 부가 단계를 추가한다.
이번 장 목표는 `testthat` 팩키지를 사용해서 정형적인 테스팅 자동화를 통해서 테스팅 작업을 좀더 쉽고 효과적으로 수행하는 방법을 시연하는데 있다.

지금까지 작업흐름은 아마도 다음과 같을 것이다:

1. 함수를 작성한다.
1. Ctrl/Cmd + Shift + L 단축키 혹은 `devtools::load_all()` 명령어를 통해서 함수를 적재한다.
1. 작성한 함수가 동작하는지 살펴보기 위해서 콘솔에서 실험한다.
1. 함수를 깔끔하게 만들고, 과정을 반복한다.

작업흐름 과정에서 코드를 _테스팅_을 했지만, 비정형으로만 작업을 수행한 것이다.
이러한 접근방법의 문제점은 3개월이 지난 뒤에 코드 베이스에 신규 기능을 추가하려면, 개발 초기 실행했던
비정형 테스트 일부를 아마도 잊어버렸을 것이다.
따라서, 잘 동작했던 코드가 깨져서 돌아기지 않기 매우 쉽게 된다.

저자가 테스트 자동화를 사용하기 시작한 이유는 너무 많은 시간을 이전에 고친 버그를 다시 고치는데 쓰고 있다는 것을 발견했기 때문이다.
코드를 작성하고 버그를 고치면서 작성한 코드가 잘 동작하는지 확인하는데 인터랙티브 테스트를 수행한다.
하지만, 저자는 테스트를 저장할 수 있는 시스템을 갖추지 않았다. 그래서, 필요해지면 테스트를 다시 실행할 수 있었다. 저자 생각에는 R 프로그래머 사이에 이러한 것이 일반적이라고 본다.
이유는 코드를 테스트하지 않기 때문이 아니라, 테스트를 자동화하지 않았기 때문이다.

이번 장에서 명령라인에서 수행하는 비정형 무작위 테스팅을 졸업하고, 정형화된 테스트 자동화(aka, 단위 테스트)로 옮겨가는 것을 학습한다.
임시방편 인터랙티브 테스트를 재현가능 스크립트로 변환하는 것이 앞단에 일부 업무부하를 주지만, 4가지 방식으로 나중에 보상을 한다:

* 더 적은 버그. 코드가 동작해야 되는 방식에 대해 명시적으로 선언했기 때문에,
  더 적은 버그를 갖게 된다. 이유는 회계학에서 복식부기가 동작하는 것과 유사하다:
  코드와 테스트 두곳에 작성한 코드 행동을 기술했기 때문에, 서로에 대해 검증할 수 있다.
  이러한 접근방법을 테스팅에 도입하면, 
  과거에 고친 버그가 결코 귀신처럼 다시 쫓아다니지 못하게 확실히 할 수 있다.
  
* 향상된 코드 구조. 테스트하기 쉬운 코드는 일반적으로 더 잘 설계되었다.
  이유는 테스트를 작성하면 어쩔 수 없이 코드의 복잡한 부분을 격리되어 동작되는 별도 함수로 쪼개야 
  되기 때문이다. 코드에 중복도 줄여준다.
  결과적으로 함수는 테스트하고, 이해하고, 동작하기 쉽게 된다
  (새로운 방식으로 조합하기도 더 쉽게 된다).
  

* 더 쉬운 재시작. (예를 들어, 구현하려는 다음 기능에 대해서) 
  항상 실패 테스트(failing test)를 생성해서 코딩 세션을 마무리한다면, 
  테스팅을 통해서 마지막 중단한 곳을 쉽게 찾아준다: 
  테스트를 통해서 다음 무엇을 수행해야 하는지 알게 해준다.
  

* 강건한 코드. 작성한 팩키지의 거의 모든 주요 기능이 연관된 테스트를 갖는 것을 알게 되면,
  신뢰감을 갖고 우연히 무언가 망가뜨린다는 걱정없이 큰 변화를 줄 수 있다.
  작업을 수행할 훨씬 더 단순한 방법이 생각났을 때 저자에게 이 기능이 유용하다.
  (대체로 해결책이 훨씬 더 단순한 이유는 중요한 사용자 사용사례(use case)를 잊어버렸다는 것이다!).

만약 이미 다른 프로그래밍 언어 단위 테스트에 친숙하다면,
`testthat`에 일부 근본적인 차이가 있음을 주목한다.
이유는 R 자체가 가슴속으로 객체지향 프로그래밍이라기 보다는 함수형 프로그래밍 언어에 가깝기 때문이다.
예를 들어, R 주요 객체지향 시스템 (S3와 S4)는 제네릭 함수에 기반하기 때문에 (즉, 메쏘드는 클래스가 아닌 함수에 속해있다), 객체와 메쏘드로 구성된 테스팅 접근법이 그다지 의미를 갖지 못한다.


## 테스트 작업흐름 {#test-workflow}

`testhat`을 사용하는 팩키지를 설정하려면, 다음을 실행한다:

```{r, eval = FALSE}
devtools::use_testthat()
```

상기 명령어는 다음을 수행한다:

1.  `tests/testthat` 디렉토리를 생성한다.

1.  testthat을 `DESCRIPTION` 파일 `Suggests` 필드에 추가한다.

1.  `tests/testthat.R` 파일을 생성해서 `R CMD check`을 실행할 때 모든 테스트를 실행한다.
     ([automated checking](#check)에서 좀더 학습할 것이다.)


설정만 마치게되면, 작업흐름은 단순하다:


1.  코드 혹은 테스트를 변형한다.

2.  Ctrl/Cmd + Shift + T 단축키 혹은 `devtools::test()` 명령어로 팩키지를 테스트한다.

3.  모든 테스트가 통과할 때까지 반복한다.

테스팅 출력결과는 다음과 같아 보인다:

    Expectation : ...........
    rv : ...
    Variance : ....123.45.

각 행은 테스트 파일을 표현한다.
각 `.` 기호는 통과한 테스트를 표현한다.
각 숫자는 실패한 테스트를 표현한다.
세부 정보를 담고 있는 실패 목록으로 숫자는 색인된다:


    1. Failure(@test-variance.R#22): Variance correct for discrete uniform rvs -----
    VAR(dunif(0, 10)) not equal to var_dunif(0, 10)
    Mean relative difference: 3
    
    2. Failure(@test-variance.R#23): Variance correct for discrete uniform rvs -----
    VAR(dunif(0, 100)) not equal to var_dunif(0, 100)
    Mean relative difference: 3.882353

테스트 각 실패는 테스트에 대한 기술 (예를 들어, "Variance correct for discrete uniform rvs"),
위치 (예를 들어, "\@test-variance.R#22"), 실패로 돌아간 사유 (예를 들어, "VAR(dunif(0, 10)) not equal to var_dunif(0, 10)") 정보를 전달한다. 목표는 모든 테스트를 통과시키는 것이다.

## 테스트 구조 {#test-structure}

테스트 파일은 `tests/testthat/`에 위치한다.
테스트 파일 명칭은 `test`로 시작해야 된다.
`stringr` 팩키지에서 나온 테스트 파일 예제가 다음에 있다:


```{r}
library(stringr)
context("String length")

test_that("str_length is number of characters", {
  expect_equal(str_length("a"), 1)
  expect_equal(str_length("ab"), 2)
  expect_equal(str_length("abc"), 3)
})

test_that("str_length of factor is length of level", {
  expect_equal(str_length(factor("a")), 1)
  expect_equal(str_length(factor("ab")), 2)
  expect_equal(str_length(factor("abc")), 3)
})

test_that("str_length of missing is missing", {
  expect_equal(str_length(NA), NA_integer_)
  expect_equal(str_length(c(NA, 1)), c(NA, 1))
  expect_equal(str_length("NA"), 2)
})
```

테스트는 계층적으로 구성되어 있다: __expectations__는 __tests__ 집단으로 묶여지고, __tests__는 __files__ 집단으로 묶여진다:


* __예상(expectation)__이 테스팅 원자에 해당된다. 
  연산에 대한 예상결과를 기술한다: 올바른 값과 올바른 클래스를 갖는가?
  오류 메시지를 내야할 때, 오류 메시지를 생성하는가?
  예상(expectation)은 시각적 점검하는 콘솔 결과값을 자동화한다.
  예상(expectation)은 `expect_`으로 시작하는 함수가 된다.
  

* __테스트(test)__는 예상(expectation) 다수를 집단으로 묶어 간단한 함수에서 출력결과를 테스트한다.
  좀더 복잡한 함수에서 단일 매개변수에 대한 가능한 범위 혹은 함수 다수로부터 단단히 연관된 기능이 포함된다.
  이것이 종종 한 기능 단위를 테스트할 때 __단위(unit)__라고 불리는 이유다.
  테스트는 `test_that()`으로 생성된다.

* __파일(file)__은 연관된 테스트 다수를 집단으로 묶는다. 
  파일은 `context()` 명령어로 사람이 읽을 수 있는 명칭이 부여된다.

다음에 각각에 대해 자세한 사항이 기술된다.

### 예상(Expectations)

예상은 가장 낮은 수준 테스팅으로 함수 호출이 기대한 바를 수행하는지 아닌지에 대해 이진 가정대입(binary assertion)한다. 모든 예상은 유사한 구조를 갖느다:

* `expect_` 으로 시작한다.

* 인자를 두개 갖는다: 첫번째는 실제 결과, 두번째는 예상하는 것.

* 만약 실제 결과값과 예상 결과값이 일치하지 않으면, `testthat`은 오류를 던진다.

정상적으로 파일 내부, 테스트 내부에 예상을 넣지만, 
직접적으로도 예상을 실행할 수 있다.
인터랙티브하게 예상을 탐색하기 쉽게 만든다.
`testthat` 팩키지에는 거의 20개 예상이 있다.
가장 중요한 것이 아래 논의된다.


*   등치를 테스트하는 기본적인 방법이 두개 있다: `expect_equal()`, `expect_identical()`.
    `expect_equal()`이 가장 흔히 사용된다: `all.equal()`을 사용해서 수치해석 허용한계에서 
    등치성을 점검한다:

    ```{r, error = TRUE}
    expect_equal(10, 10)
    expect_equal(10, 10 + 1e-7)
    expect_equal(10, 11)
    ```
  
    만약 정확한 등치성을 시험하거나, 환경(environment)같은 외래 객체와 비교가 필요하다면,
    `expect_identical()`을 사용한다. 이 함수는 `identical()` 위에서 빌드되었다:

    ```{r, error = TRUE}
    expect_equal(10, 10 + 1e-7)
    expect_identical(10, 10 + 1e-7)
    ```

*   `expect_match()`는 정규표현식에 문자 벡터를 매칭한다.
    선택옵션 `all` 인자를 통해 모든 요소 혹은 단지 요소 하나만 매칭할지를 제어한다.
    `grepl()` 명령어로 강력한 기능이 부여된다 (`ignore.case = FALSE` 혹은 `fixed = TRUE` 같은
    부가 인자가 매개변수로 전달된다).


    ```{r, error = TRUE}
    string <- "Testing is fun!"

    expect_match(string, "Testing") 
    # Fails, match is case-sensitive
    expect_match(string, "testing")

    # Additional arguments are passed to grepl:
    expect_match(string, "testing", ignore.case = TRUE)
    ```

*   4가지 `expect_match()` 변형 명령어로 다른 결과 유형을 점검한다:
    `expect_output()`은 출력결과를 점검한다; `expect_message()`는 메시지를 점검한다;
    `expect_warning()`은 경고를 점검한다; `expect_error()`은 오류를 점검한다.


    ```{r, error = TRUE}
    a <- list(1:10, letters)

    expect_output(str(a), "List of 2")
    expect_output(str(a), "int [1:10]", fixed = TRUE)

    expect_message(library(mgcv), "This is mgcv")
    ```

    `expect_message()`, `expect_warning()`, `expect_error()` 명령어에 두번째 인자를 공백으로 남겨두면,
    메시지, 경고, 오류가 생성되었는지만 확인한다.
    하지만, 일반적으로 명시적으로 메시지로부터 테스트 일부를 제공하는 것이 더 낫다.
    
    
    ```{r, error = TRUE}  
    expect_warning(log(-1))
    expect_error(1 / "a") 

    # But always better to be explicit
    expect_warning(log(-1), "NaNs produced")
    expect_error(1 / "a", "non-numeric argument")

    # Failure to produce a warning or error when expected is an error
    expect_warning(log(0))
    expect_error(1 / 2) 
    ```

*   `expect_is()` 명령어를 통해서 특정된 클래스에서 객체가 `inherit()` 상속되었는지 점검한다.

    ```{r, error = TRUE}
    model <- lm(mpg ~ wt, data = mtcars)
    expect_is(model, "lm")
    expect_is(model, "glm")
    ```

*   만약 어떤 예상도 필요한 것을 수행하지 않는다면, `expect_true()` 와 `expect_false()`이 유용하다.

*   때때로, 결과가 무엇이 되어야 하는지 알지 못하거나, 혹은 너무 복잡해서 코드로 재생성하기가 쉽지 않다.
    이런 경우에, 취할 수 있는 가장 최선은 결과가 가장 마지막 수행결과와 동일한지 점검하는 것이다.
    `expect_equal_to_reference()`으로 첫 실행 결과를 캐쉬로 갖고 나서, 후속 실행결과와 비교한다.
    만약 어떤 연유로 인해서 결과가 변경되면, 캐쉬 (*) 파일을 삭제만하고 다시 테스트한다.

일련의 예상을 실행하는 것이 유용한데 이유는 작성한 코드가 예상한대로 동작하는지 확실히 해주기 때문이다.
심지어 함수 내부에도 예상을 사용해서 입력값이 기대한 것인지 점검한다.
하지만, 뭔가 잘못되면 그다지 유용하지는 않다.
이를 통해 무언가 기대한 것이 아니라는 것만 알게 된다. 예상 목적을 알지 못하기 때문이다.
다음에 기술되는 테스트는 예상을 일관된 블록을 구조화해서 전반적인 예상 집합 목적을 기술한다.


## 테스트 작성 {#test-tests}

각 테스트는 정보가 되는 명칭을 가져야 되고, 단일 기능 단위만을 다뤄야만 된다.
기본적인 생각은 테스트가 실패할 때, 무엇이 잘못되었는지와 코드에서 문제점이 어디에 있는지 찾을 수 있게 한다.
테스트 명칭과 코드 블록을 인자로 갖는 `test_that()` 명령어를 사용해서 신규 테스트를 생성한다.
테스트 명칭은 "Test that ..." 완전한 문장이 되어야 한다. 코드 블록은 예상 집합이다.

예상을 테스트로 어떻게 구조화할지는 작성자에 달려있다.
주요한 점은 테스트와 연관된 메시지가 정보가 되게 작성되어 문제 원천으로 빠르게 좁혀갈 수 있어야 된다.
한 테스트에 너무 많은 예상을 넣는 것을 피하라 - 좀더 커다란 적은 수의 테스트 보다는 더 많은 작은 테스트를 갖는게 더 낫다.


각 테스트는 자체 환경에서 실행되고 그 자체로 완비되어야 한다.
하지만, 동작(action)이 R 실행환경에 영향을 준 다음에 정리하는 방법을 `testthat`은 갖고 있지 않다: 


* 파일시스템: 파일 생성과삭제, 작업 디렉토리 변경 등.

* 검색 경로: `library()`, `attach()`.

* `options()` 와 `par()` 같은 전역 선택옵션.

테스트에 상기 동작(action)을 사용하면, 본인 스스로 정리할 필요가 있다.

다른 많은 테스팅 팩키지가 설정 및 해제 메쏘드를 갖고서 각 테스트 이전과 이후에 자동으로 실행되지만, 
`testthat` 팩키지에서는 그다지 중요하지 않다. 이유는 테스트 외부에 객체를 생성하고, 
R의 '변경에 복사(copy-on-modify)' 시맨틱을 사용해서 테스트 실행 간에 변경이 일어나지 않게 한다.
다른 동작을 정리하는데는 정규 R 함수를 사용한다.


### 테스트 대상 (What to test)

> 무언가를 출력문장(print statement) 혹은 디버거 표현식으로 타이핑하려는 유혹이 있을 때마다,
> 그러지 말고 대신에 테스트로 작성하라. --- 마틴 파울러(Martin Fowler)

테스트 작성에 있어 미묘한 균형이 있다.
매번 테스트를 작성하면 우연히 코드를 변경하지 않게 된다; 하지만, 의도적으로 코드를 변경하기 더 어렵게도 한다.
테스트 작성에 대한 일반적으로 훌륭한 조언을 하기는 어렵지만, 다음 사항이 도움이 될 수 있다:


* 함수 외부 인터페이스에 집중하라 - 만약 내부 인터페이스를 테스트 한다면, 
  향후에 구현사항을 변경하기가 더 어렵다. 왜냐하면 코드를 변경해야 될 뿐만 아니라,
  테스트 모두를 갱신해야될 필요도 있기 때문이다.


* 한 테스트 그리고 오직 한 테스트에서 각 행동을 테스트하려고 해라.
  그러면, 만약 나중에 행동이 변경되면, 단일 테스트만 갱신만 필요하게 된다.

* 확실을 갖는 잘 동작하는 단순한 코드 테스트는 삼가라.
  대신에 확신을 갖지 못한, 부서지기 쉬운, 복잡한 상호의존성을 갖는 코드에 더 많은 시간을 투여하라.
  이것이 말하는 바는, 문제가 단순해서 어떤 테스트도 필요하지 않다고 
  잘못 가정한 곳에서 저자는 종종 대부분의 실수를 발견한다.

* 버그를 발견한 곳에 테스트를 항상 작성하라.
  우선 테스트 철학을 도입하는게 도움이 된다.
  항시 테스트를 작성함으로써 시작하고 나서, 테스트를 통과하는 코드를 작성한다.
  중요한 문제해결 전략을 떠올리게 한다: 만약 문제를 해결했다면 어떻게 알 수 있는지, 
  성공 기준을 설정하고 시작하라.
  

### 테스트 건너뛰기

때때로, 테스트 수행이 불가능하다 - 인터넷 연결이 되지 않거나 중요한 파일을 분실했을 수도 있다.
불행하게도, 또다른 가능한 사유가 이 단순한 규칙에서 나온다: 
코드를 작성하는데 더 많은 컴퓨터를 사용하면 할 수록, 테스트 모두를 더 수행할 것 같지 않다.
짧게 말해서, 실패를 얻는 대신에 단지 테스트를 건너뛰고 싶을 때가 있다.
이런 욕구를 충족시키기 위해서, `skip()` 함수를 사용한다 - 오류를 던지기보다 출력결과에 `S` 만 단순히 출력한다.


```{r, eval = FALSE}
check_api <- function() {
  if (not_working()) {
    skip("API not available")
  }
}

test_that("foo api returns bar when given baz", {
  check_api()
  ...
})
```

### 본인 정의 테스팅 도구 구축

테스트를 더 많이 작성함에 따라 코드에 중복을 인지하게 된다.
예를 들어, `library(lubridate)` 팩키지로부터 `floor_date()` 함수 테스트 일부가 다음 코드에 나와있다.
예상(expectation)이 7개 있는데 날짜를 반올림한 결과를 가장 근접한 초, 분, 시 등 정보와 비교하여 점검한다.
(버그 가능성을 높이는) 어마어마한 중복이 있다. 그래서 신규 함수로 공통된 행동을 추출하고 싶다.


```{r}
library(lubridate)
test_that("floor_date works for different units", {
  base <- as.POSIXct("2009-08-03 12:01:59.23", tz = "UTC")

  expect_equal(floor_date(base, "second"), 
    as.POSIXct("2009-08-03 12:01:59", tz = "UTC"))
  expect_equal(floor_date(base, "minute"), 
    as.POSIXct("2009-08-03 12:01:00", tz = "UTC"))
  expect_equal(floor_date(base, "hour"),   
    as.POSIXct("2009-08-03 12:00:00", tz = "UTC"))
  expect_equal(floor_date(base, "day"),    
    as.POSIXct("2009-08-03 00:00:00", tz = "UTC"))
  expect_equal(floor_date(base, "week"),   
    as.POSIXct("2009-08-02 00:00:00", tz = "UTC"))
  expect_equal(floor_date(base, "month"),  
    as.POSIXct("2009-08-01 00:00:00", tz = "UTC"))
  expect_equal(floor_date(base, "year"),   
    as.POSIXct("2009-01-01 00:00:00", tz = "UTC"))
})
```

각 예상을 좀더 간략하게 만드는데 도움말 함수를 한쌍을 정의해서 시작한다.
이와 같이 작성하면 각 테스트가 한 줄에 꼭 맞는다. 
그렇게 해서, 실제값과 예상값을 잘 맞춰서 차이점을 좀더 쉽게 식별하게 한다:


```{r}
test_that("floor_date works for different units", {
  base <- as.POSIXct("2009-08-03 12:01:59.23", tz = "UTC")
  floor_base <- function(unit) floor_date(base, unit)
  as_time <- function(x) as.POSIXct(x, tz = "UTC")

  expect_equal(floor_base("second"), as_time("2009-08-03 12:01:59"))
  expect_equal(floor_base("minute"), as_time("2009-08-03 12:01:00"))
  expect_equal(floor_base("hour"),   as_time("2009-08-03 12:00:00"))
  expect_equal(floor_base("day"),    as_time("2009-08-03 00:00:00"))
  expect_equal(floor_base("week"),   as_time("2009-08-02 00:00:00"))
  expect_equal(floor_base("month"),  as_time("2009-08-01 00:00:00"))
  expect_equal(floor_base("year"),   as_time("2009-01-01 00:00:00"))
})
```

한단계 더 나아가 사용자 정의 예상 함수(expectation function)도 생성할 수 있다:

```{r}
base <- as.POSIXct("2009-08-03 12:01:59.23", tz = "UTC")

expect_floor_equal <- function(unit, time) {
  expect_equal(floor_date(base, unit), as.POSIXct(time, tz = "UTC"))
}
expect_floor_equal("year", "2009-01-01 00:00:00")
```

하지만, 만약 예상이 실패한다면, 그다지 정보가 되는 출력결과를 반환하지는 못한다:

```{r, error = TRUE}
expect_floor_equal("year", "2008-01-01 00:00:00")
```

대신에 [비표준 평가(non-standard evaluation)](http://adv-r.had.co.nz/Computing-on-the-language.html)를 사용해서 좀더 도움이 되는 뭔가를 만들어 낸다.
중요한 점은 `bquote()` 와 `eval()`을 사용하는 것이다.
다음 `bquote()` 호출에서, `.(x)` 사용에 주목한다 - `()` 콘텐츠가 호출에 삽입된다.

```{r, error = TRUE}
expect_floor_equal <- function(unit, time) {
  as_time <- function(x) as.POSIXct(x, tz = "UTC")
  eval(bquote(expect_equal(floor_date(base, .(unit)), as_time(.(time)))))
}
expect_floor_equal("year", "2008-01-01 00:00:00")
```

이런 유형의 리팩터링(refactoring)은 종종 가치가 있는데 이유는 중복되는 코드를 제거하면
무엇이 변경되는지 알아내기가 훨씬 더 쉽다.
가독성 높은 테스트를 통해서 작성한 코드가 올바르다는 더 깊은 신뢰감이 생긴다.


```{r}
test_that("floor_date works for different units", {
  as_time <- function(x) as.POSIXct(x, tz = "UTC")
  expect_floor_equal <- function(unit, time) {
    eval(bquote(expect_equal(floor_date(base, .(unit)), as_time(.(time)))))
  }

  base <- as_time("2009-08-03 12:01:59.23")
  expect_floor_equal("second", "2009-08-03 12:01:59")
  expect_floor_equal("minute", "2009-08-03 12:01:00")
  expect_floor_equal("hour",   "2009-08-03 12:00:00")
  expect_floor_equal("day",    "2009-08-03 00:00:00")
  expect_floor_equal("week",   "2009-08-02 00:00:00")
  expect_floor_equal("month",  "2009-08-01 00:00:00")
  expect_floor_equal("year",   "2009-01-01 00:00:00")
})
```

## 테스트 파일 {#test-files}

테스트 최상위 구조가 파일이다.
각 파일에는 간략하게 콘텐츠 내용을 기술하는 `context()` 호출이 하나 담겨있다.
`R/` 디렉토리에 파일처럼, 원하는 바대로 테스트를 자유로이 구조화한다.
하지만 다시한번, 양극단은 명확히 나쁘다 (모든 테스트를 파일 하나, 각 테스트마다 파일 한개씩).
작성자에 잘 맞는 적절한 균형점을 찾아보세요.
복잡한 각 함수마다 테스트 파일을 하나두고 시작하는 것이 좋은 출발점이 된다.

## CRAN 주의사항 {#test-cran}

지원하는 모든 CRAN 플랫폼에 맞춰 테스트를 실행한다: 윈도우, 맥, 리눅스, 솔라리스.
가슴에 새겨할 될 몇가지가 있다:


* 상대적으로 신속하게 테스트가 실행될 필요가 있다 - 1분 이내로 목표를 잡는다.
  장시간 소요되는 테스트 시작점에 `skip_on_cran()`을 위치시켜서 CRAN에서 실행되지 않게 한다.
  - 여전히 로컬 컴퓨터에서 실행되어야 하지만, CRAN에서는 실행되지 않게 한다.

* 항상 영어 (`LANGUAGE=EN`)와 C 정렬순서 (`LC_COLLATE=C`)로 테스트가 실행되게 주의한다.
  이를 통해 플랫폼간에 거짓 차이(spurious difference)를 최소화한다.
  
* CRAN 컴퓨터에서 변화가 생길 여지가 있는 것을 테스트할 때 주의힌다.
  얼마나 시간이 오래 소요될지 테스트하거나 (왜냐하면 CRAN 컴퓨터가 종종 과부하 걸린다) 
  병렬 코드를 테스트하는 것은 위험하다 (왜냐하면 CRAN측에서 병렬로 다수 팩키지 테스트를 
  실행하기 때문에 다중 코어가 항상 이용가능한 것은 아니다.).
  수치 정밀도도 플랫폼마다 다를 수 있다 (R 32-비트 버젼에서 종종 정도가 떨어진다). 그래서
  `expect_identical()` 보다는 `expect_equal()`을 사용한다.

[tdd]:http://en.wikipedia.org/wiki/Test-driven_development
[extreme-programming]:http://en.wikipedia.org/wiki/Extreme_programming
